name: AI 日报数据收集

on:
  # 定时任务：每天早上8点和晚上8点 (北京时间)
  schedule:
    - cron: '0 0 * * *'    # 早上8点北京时间 (UTC 0点)
    - cron: '0 12 * * *'   # 晚上8点北京时间 (UTC 12点)
  
  # 允许手动触发
  workflow_dispatch:
    inputs:
      sources:
        description: '指定爬取源 (多个用逗号分隔，如: arxiv,github)'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - arxiv
          - github
          - rss
          - papers-with-code
          - stackoverflow
          - arxiv,github
          - arxiv,rss
          - github,rss
      use_source_config:
        description: '使用智能源配置 (推荐)'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'
      max_results:
        description: '统一最大结果数 (仅当关闭智能配置时使用)'
        required: false
        default: '10'
        type: string
      continue_on_error:
        description: '遇到错误时继续执行其他源'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'
      runner_type:
        description: 'Runner 类型选择'
        required: false
        default: 'github-hosted'
        type: choice
        options:
          - 'github-hosted'
          - 'self-hosted'

jobs:
  # 准备阶段：解析数据源
  prepare:
    runs-on: ubuntu-22.04
    timeout-minutes: 5
    outputs:
      sources: ${{ steps.parse-sources.outputs.sources }}
    
    steps:
      - name: 解析数据源
        id: parse-sources
        run: |
          SOURCES_INPUT="${{ github.event.inputs.sources || 'all' }}"
          echo "输入的数据源: $SOURCES_INPUT"
          
          if [ "$SOURCES_INPUT" = "all" ]; then
            # 拆分所有可用数据源
            ALL_SOURCES=("arxiv" "github" "rss" "papers-with-code" "stackoverflow")
            SOURCES_JSON="["
            for i in "${!ALL_SOURCES[@]}"; do
              if [ $i -gt 0 ]; then
                SOURCES_JSON+=","
              fi
              SOURCES_JSON+="\"${ALL_SOURCES[$i]}\""
            done
            SOURCES_JSON+="]"
            
            echo "sources=$SOURCES_JSON" >> $GITHUB_OUTPUT
            echo "使用 Matrix 模式处理所有数据源: $SOURCES_JSON"
          else
            # 拆分指定的多个数据源
            IFS=',' read -ra SOURCE_ARRAY <<< "$SOURCES_INPUT"
            SOURCES_JSON="["
            for i in "${!SOURCE_ARRAY[@]}"; do
              SOURCE=$(echo "${SOURCE_ARRAY[$i]}" | xargs)  # 去除空格
              if [ $i -gt 0 ]; then
                SOURCES_JSON+=","
              fi
              SOURCES_JSON+="\"$SOURCE\""
            done
            SOURCES_JSON+="]"
            
            echo "sources=$SOURCES_JSON" >> $GITHUB_OUTPUT
            echo "使用 Matrix 模式处理指定数据源: $SOURCES_JSON"
          fi

  # 数据收集任务
  collect-data:
    needs: prepare
    # 动态选择 runner 类型
    runs-on: ${{ github.event.inputs.runner_type == 'self-hosted' && 'self-hosted' || 'ubuntu-22.04' }}
    timeout-minutes: 20    # 单个数据源超时时间减少
    
    # 动态 matrix 策略
    strategy:
      fail-fast: ${{ github.event.inputs.continue_on_error != 'true' }}
      matrix:
        source: ${{ fromJson(needs.prepare.outputs.sources) }}
    
    # 添加环境优化
    env:
      NODE_OPTIONS: '--max-old-space-size=4096'  # 增加 Node.js 内存限制
      FORCE_COLOR: '1'  # 强制彩色输出，便于调试
    
    steps:
      - name: 检出代码
        uses: actions/checkout@v4
      
      - name: 安装 pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 8
      
      - name: 设置 Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'pnpm'
          registry-url: 'https://registry.npmjs.org'
      
      - name: 安装依赖
        run: |
          echo "安装依赖开始时间: $(date)"
          pnpm install
          echo "安装依赖完成时间: $(date)"
      
      - name: 编译 TypeScript 脚本
        run: |
          echo "开始编译 TypeScript 文件..."
          rm -rf dist/scripts/
          mkdir -p dist/scripts/
          npx tsc scripts/collectDataToSupabase.ts --outDir dist/scripts --module commonjs --target es2020 --esModuleInterop true --allowSyntheticDefaultImports true --skipLibCheck true --declaration false
          npx tsc scripts/updateCategoryStats.ts --outDir dist/scripts --module commonjs --target es2020 --esModuleInterop true --allowSyntheticDefaultImports true --skipLibCheck true --declaration false
          echo "编译完成"
          echo "检查编译输出:"
          find dist/scripts/ -name "*.js" -type f
      
      - name: 配置环境变量
        run: |
          echo "NODE_ENV=production" >> $GITHUB_ENV
          echo "TZ=Asia/Shanghai" >> $GITHUB_ENV
          echo "CURRENT_SOURCE=${{ matrix.source }}" >> $GITHUB_ENV
      
      - name: 环境信息
        run: |
          echo "Node.js: $(node --version)"
          echo "pnpm: $(pnpm --version)"
          echo "系统: $(uname -r)"
          echo "当前处理数据源: ${{ matrix.source }}"
      
      - name: 验证环境变量
        run: |
          echo "验证关键环境变量..."
          [ -n "$SUPABASE_URL" ] && echo "✅ SUPABASE_URL" || echo "❌ SUPABASE_URL"
          [ -n "$SUPABASE_ANON_KEY" ] && echo "✅ SUPABASE_ANON_KEY" || echo "❌ SUPABASE_ANON_KEY"
          [ -n "$SUPABASE_SERVICE_ROLE_KEY" ] && echo "✅ SUPABASE_SERVICE_ROLE_KEY" || echo "❌ SUPABASE_SERVICE_ROLE_KEY"
          [ -n "$GH_TOKEN" ] && echo "✅ GH_TOKEN" || echo "❌ GH_TOKEN"
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
      
      - name: 运行数据收集 - ${{ matrix.source }}
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
        run: |
          echo "开始运行数据收集 - 数据源: ${{ matrix.source }}"
          
          # 构建命令参数
          CURRENT_SOURCE="${{ matrix.source }}"
          USE_SOURCE_CONFIG="${{ github.event.inputs.use_source_config || 'true' }}"
          MAX_RESULTS="${{ github.event.inputs.max_results || '10' }}"
          
          # 查找编译后的脚本文件
          SCRIPT_FILE=$(find dist/scripts/ -name "collectDataToSupabase.js" -type f | head -1)
          
          if [ -z "$SCRIPT_FILE" ]; then
            echo "❌ 未找到编译后的脚本文件"
            exit 1
          fi
          
          echo "✅ 找到脚本文件: $SCRIPT_FILE"
          
          CMD="node $SCRIPT_FILE"
          CMD="$CMD --sources=$CURRENT_SOURCE"
          CMD="$CMD --timeout=20"
          CMD="$CMD --verbose"
          
          if [ "$USE_SOURCE_CONFIG" = "true" ]; then
            CMD="$CMD --use-source-config"
          else
            CMD="$CMD --max-results=$MAX_RESULTS"
          fi
          
          # 单个数据源失败不影响其他源（通过 strategy.fail-fast 控制）
          CMD="$CMD --continue-on-error"
          
          echo "执行命令: $CMD"
          eval $CMD
      
      - name: 更新分类统计 - ${{ matrix.source }}
        if: success()
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "开始更新分类统计..."
          
          # 查找编译后的分类统计脚本
          STATS_SCRIPT=$(find dist/scripts/ -name "updateCategoryStats.js" -type f | head -1)
          
          if [ -z "$STATS_SCRIPT" ]; then
            echo "⚠️ 未找到分类统计脚本，跳过统计更新"
          else
            echo "✅ 找到分类统计脚本: $STATS_SCRIPT"
            echo "执行分类统计更新..."
            node $STATS_SCRIPT --verbose || echo "⚠️ 分类统计更新失败，但不影响主流程"
          fi
      
      - name: 上传数据收集日志
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: collection-log-${{ matrix.source }}
          path: collection_log.txt
          retention-days: 7
      
      - name: 任务完成状态 - ${{ matrix.source }}
        if: always()
        run: |
          echo "=== 数据源 ${{ matrix.source }} 执行完成 ==="
          echo "完成时间: $(date '+%Y-%m-%d %H:%M:%S %Z')"
          echo "触发方式: ${{ github.event_name }}"
          
          if [ -f collection_log.txt ]; then
            echo "收集结果概览:"
            tail -10 collection_log.txt
          fi

  # 汇总任务
  summary:
    needs: [prepare, collect-data]
    runs-on: ubuntu-22.04
    if: always()
    timeout-minutes: 5
    
    steps:
      - name: 下载所有日志
        uses: actions/download-artifact@v4
        with:
          path: logs/
      
      - name: 生成执行汇总
        run: |
          echo "=== AI 日报数据收集执行汇总 ==="
          echo "执行时间: $(date '+%Y-%m-%d %H:%M:%S %Z')"
          echo "触发方式: ${{ github.event_name }}"
          echo "处理的数据源: ${{ needs.prepare.outputs.sources }}"
          echo "执行模式: Matrix 并行处理"
          echo ""
          
          # 统计各数据源执行结果
          if [ -d "logs" ]; then
            echo "各数据源执行结果:"
            for log_dir in logs/collection-log-*/; do
              if [ -d "$log_dir" ]; then
                source_name=$(basename "$log_dir" | sed 's/collection-log-//')
                echo "📊 数据源: $source_name"
                if [ -f "$log_dir/collection_log.txt" ]; then
                  echo "   最后几行日志:"
                  tail -3 "$log_dir/collection_log.txt" | sed 's/^/   /'
                else
                  echo "   ❌ 未找到日志文件"
                fi
                echo ""
              fi
            done
          else
            echo "未找到日志目录"
          fi 